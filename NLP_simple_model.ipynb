{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP simple model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOOR0KXhjnFX6bYV73+iUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaleem500bc/Simple-NLP-linear-model/blob/master/NLP_simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ktxxtRXAO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "41928025-ad3e-4c17-c6c6-de34a356ce8c"
      },
      "source": [
        "!pip install torchtext --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f9/224b3893ab11d83d47fde357a7dcc75f00ba219f34f3d15e06fe4cb62e05/torchtext-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOQnE9UogCka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# import torchviz\n",
        "from torch.nn import functional as F\n",
        "import torchtext \n",
        "from torchtext import datasets as ttDatasets\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvZID5KIMXxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9273a0b1-9509-4ba2-e21f-1d51d4f5af4f"
      },
      "source": [
        "train_dataset,test_dataset = torchtext.datasets.text_classification.DATASETS['AG_NEWS']('agNews',\n",
        "                  ngrams=2,vocab=None\n",
        "                  )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ag_news_csv.tar.gz: 11.8MB [00:00, 42.1MB/s]\n",
            "120000lines [00:07, 16570.48lines/s]\n",
            "120000lines [00:16, 7083.41lines/s]\n",
            "7600lines [00:00, 7711.60lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCAWZhdlY4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "  labels = torch.tensor([l for l,t in data])\n",
        "  text = [t for l,t in data]\n",
        "  textLen = [0]+[len(t) for l,t in data]\n",
        "  offsets = torch.tensor(textLen[:-1]).cumsum(dim=0)\n",
        "  text = torch.cat(text)\n",
        "  return text,labels,offsets"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8UpKxDEX4_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BatchSize= 16\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset,BatchSize,shuffle=True,collate_fn=collate_fn)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGGCs11ZquWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class lModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.embd = nn.EmbeddingBag(vocab_size,2)\n",
        "    self.f1 = nn.Linear(2,32)\n",
        "    self.f2 = nn.Linear(32,64)\n",
        "    self.f3 = nn.Linear(64,32)\n",
        "    self.f = nn.Linear(32,4)\n",
        "  def forward(self,text,offsets):\n",
        "    x = self.embd(text,offsets)\n",
        "    x = F.relu(self.f1(x))\n",
        "    x = F.relu(self.f2(x))\n",
        "    x = F.relu(self.f3(x))\n",
        "    x = F.relu(self.f(x))\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3dvNNonvWAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(train_dataset.get_vocab())\n",
        "linearModel = lModel(vocab_size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ181e25Gx_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6d2ef605-897c-4d4d-80e0-7541121810cb"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(linearModel.parameters())\n",
        "\n",
        "linearModel.to(\"cuda\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lModel(\n",
              "  (embd): EmbeddingBag(1308844, 2, mode=mean)\n",
              "  (f1): Linear(in_features=2, out_features=32, bias=True)\n",
              "  (f2): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (f3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (f): Linear(in_features=32, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxUhf6YHJWXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "78472358-72a3-4221-9286-1bd9da5afe11"
      },
      "source": [
        "epoch = 5\n",
        "for e in range(epoch):\n",
        "  totalLoss = 0\n",
        "  for txt,lbl,offset in dataloader:\n",
        "    txt, offset, lbl = txt.to(\"cuda\"),offset.to(\"cuda\"), lbl.to(\"cuda\")\n",
        "\n",
        "    out = linearModel(txt,offset)\n",
        "    optim.zero_grad()    \n",
        "    loss = criterion(out,lbl)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    totalLoss = totalLoss + loss.item()\n",
        "    optim.step()\n",
        "  print(totalLoss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6250.1799277588725\n",
            "3403.237520221621\n",
            "2536.8534248247743\n",
            "2022.162873136811\n",
            "1642.9876332059503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGjPntV7Zt-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19775bf5-5f93-417e-8bdc-347db84170d1"
      },
      "source": [
        "class_name = {0:'world',1:'sports',2:'Business',3:'sci/tech'}\n",
        "\n",
        "\n",
        "sentence = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "\n",
        "vocab = train_dataset.get_vocab()\n",
        "tokens = tokenizer(sentence)\n",
        "ngrams = torchtext.data.utils.ngrams_iterator(tokens,2)\n",
        "text = torch.tensor([vocab[i] for i in ngrams]).to(\"cuda\")\n",
        "\n",
        "\n",
        "out = linearModel(text,torch.tensor([0]).to(\"cuda\"))\n",
        "print(class_name[torch.argmax(out).item()])\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sports\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yXQmYkaH1uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}